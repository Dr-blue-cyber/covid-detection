{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"covid_predec_CNN.ipynb","provenance":[],"collapsed_sections":["xDogwArL-omG","6bkq5VBK-233","YUkndozKW33h"],"authorship_tag":"ABX9TyN6idD17iPBnbZFAT20fLyK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"xDogwArL-omG"},"source":["#imports"]},{"cell_type":"code","metadata":{"id":"BIwfmg18YMEo","executionInfo":{"status":"ok","timestamp":1633495480478,"user_tz":-330,"elapsed":665,"user":{"displayName":"Sūråj Bhanarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuO4qvUng3Kq2OxSVB5UBFaCFJUUFoZWLannUw=s64","userId":"14139449971073476462"}}},"source":["\n","import numpy as np \n","import matplotlib.pyplot as plt"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wCSguA_KYxjA"},"source":["import some deep learning layers\n","droupout for pevent overfitting ,and whatever output we havewe have to pass it over ANN so use Flatten\n","we can use functional api or Sequential module\n","keras.preprocessing for image\n"]},{"cell_type":"code","metadata":{"id":"a7n1DrlCY1lr","executionInfo":{"status":"ok","timestamp":1633495372782,"user_tz":-330,"elapsed":2628,"user":{"displayName":"Sūråj Bhanarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuO4qvUng3Kq2OxSVB5UBFaCFJUUFoZWLannUw=s64","userId":"14139449971073476462"}}},"source":["import keras\n","from keras.layers import Dense, Conv2D, MaxPool2D, Dropout, Flatten\n","from keras.models import Sequential\n","from keras.preprocessing import image"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6bkq5VBK-233"},"source":["#load data \n","data over here is images"]},{"cell_type":"markdown","metadata":{"id":"oBM4vvwSbiyT"},"source":["import our dataset here use by data generator bcz with data generator we can do some data augmentation\n","**pixel values go from 0 to 125**\n","1/255 means every pixel rescale by 255"]},{"cell_type":"code","metadata":{"id":"ZtPzpliVbevY","executionInfo":{"status":"ok","timestamp":1633495487748,"user_tz":-330,"elapsed":645,"user":{"displayName":"Sūråj Bhanarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuO4qvUng3Kq2OxSVB5UBFaCFJUUFoZWLannUw=s64","userId":"14139449971073476462"}}},"source":["train_datagen = image.ImageDataGenerator(\n","    rescale = 1/255, horizontal_flip = True, zoom_range = 0.2, shear_range = 0.2\n",")"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YUkndozKW33h"},"source":["# call our dataset here\n","1. set tirget size by default it 256 we and remain the same  target(x,y) and x, y are the axis\n","2. as we perform binary classification we have to change class_mode"]},{"cell_type":"code","metadata":{"id":"pEBFaUU7X48r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633496071590,"user_tz":-330,"elapsed":683,"user":{"displayName":"Sūråj Bhanarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuO4qvUng3Kq2OxSVB5UBFaCFJUUFoZWLannUw=s64","userId":"14139449971073476462"}},"outputId":"e3b1a077-a4fb-4bf3-dcc6-da8a4722cd90"},"source":["train_data = train_datagen.flow_from_directory(directory=\"/content/dataset/train\", target_size= (256,256), batch_size= 16, class_mode = 'binary')"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 56 images belonging to 3 classes.\n"]}]},{"cell_type":"markdown","metadata":{"id":"Guqm11sd9guv"},"source":["to check which classes we have"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KQpSFg979GQP","executionInfo":{"status":"ok","timestamp":1633496124640,"user_tz":-330,"elapsed":704,"user":{"displayName":"Sūråj Bhanarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuO4qvUng3Kq2OxSVB5UBFaCFJUUFoZWLannUw=s64","userId":"14139449971073476462"}},"outputId":"27f62a56-834b-4b5c-fcae-a9d76e21bca6"},"source":["train_data.class_indices "],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'.ipynb_checkpoints': 0, 'covid': 1, 'normal': 2}"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"odmgBcI2nBjs"},"source":["# Test Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CgzbvU469txY","executionInfo":{"status":"ok","timestamp":1633500820034,"user_tz":-330,"elapsed":694,"user":{"displayName":"Sūråj Bhanarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuO4qvUng3Kq2OxSVB5UBFaCFJUUFoZWLannUw=s64","userId":"14139449971073476462"}},"outputId":"cdc799d7-74e1-49d1-c0e1-41c4bd773840"},"source":["test_datagen = image.ImageDataGenerator(\n","    rescale = 1/255\n",")\n","test_data = test_datagen.flow_from_directory(directory=\"/content/dataset/test\", target_size= (256,256), batch_size= 16, class_mode = 'binary')"],"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 72 images belonging to 3 classes.\n"]}]},{"cell_type":"markdown","metadata":{"id":"nDKClr1UPlBN"},"source":["CLASS VALUE CHECK "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FUuiRoRlPZ8X","executionInfo":{"status":"ok","timestamp":1633500916793,"user_tz":-330,"elapsed":882,"user":{"displayName":"Sūråj Bhanarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuO4qvUng3Kq2OxSVB5UBFaCFJUUFoZWLannUw=s64","userId":"14139449971073476462"}},"outputId":"6ff38734-f66d-42a6-900b-5e6b3b5dc34e"},"source":["train_data.class_indices"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'.ipynb_checkpoints': 0, 'covid': 1, 'normal': 2}"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"L8HUop5K_HjP"},"source":["#building our Deep Neural model( CNN MODEL )\n","1. first of we initialise sequential \n","2. adding CNN layers \n","  2.1 add convulation layers and we have no. featurs \n","  2.2 kerneel size is 3x3 bcz its indutrial standard \n","  2.3 and we have involve non-linearity so we use RELU \n","  2.4 input_usually same as in train and teast data and 3 is bcz its an rgb image  \n","### done with first convulation layer and simply we add couple most\n","\n","\n","input_shapes suppose to only first time in first layer\n","  2.2 we increase no. of featues \n","  2.3 adding max poll layer\n","  2.3 and finnaly we drop some layers\n","\n","3. so similarly weare gone add five convulation layer  (2 is first complete layer) \n","  and change no. of filters\n","\n","\n","4. when done with this layer we r gone flatten this layer \n","\n","5. and now just pass oue DENSE layer.Dense Layer is ANN or multi layer perceptrons\n","\n","6. dropout rate is 50% bcz if dont drop this out our model would end up with our fitting and this will lead us to our loss\n","7. andd now comming down to final output\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"-pQh6ut4_WcZ","executionInfo":{"status":"ok","timestamp":1633500836537,"user_tz":-330,"elapsed":823,"user":{"displayName":"Sūråj Bhanarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuO4qvUng3Kq2OxSVB5UBFaCFJUUFoZWLannUw=s64","userId":"14139449971073476462"}}},"source":["model = Sequential()\n","\n","model.add(Conv2D(filters= 32, kernel_size=(3,3), activation= 'relu', input_shape = (256, 256, 3)))\n","\n","model.add(Conv2D(filters= 64, kernel_size=(3,3), activation= 'relu'))\n","model.add(MaxPool2D())\n","model.add(Dropout(rate = 0.25))\n","\n","\n","model.add(Conv2D(filters= 64, kernel_size=(3,3), activation= 'relu'))\n","model.add(MaxPool2D())\n","model.add(Dropout(rate = 0.25))\n","\n","\n","model.add(Conv2D(filters= 128, kernel_size=(3,3), activation= 'relu'))\n","model.add(MaxPool2D())\n","model.add(Dropout(rate = 0.25))\n","\n","\n","model.add(Flatten()) \n","model.add(Dense(units= 64, activation = 'relu'))\n","model.add(Dropout(rate= 0.50)) \n","model.add(Dense(units= 1, activation= 'sigmoid'))\n","\n","\n","model.compile(loss = keras.losses.binary_crossentropy, optimizer = \"adam\", metrics = ['acc'])\n","\n","\n"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZSPfWQByIlkT"},"source":["for how oue model looks like"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s5kWxKRLIqxY","executionInfo":{"status":"ok","timestamp":1633500837229,"user_tz":-330,"elapsed":5,"user":{"displayName":"Sūråj Bhanarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuO4qvUng3Kq2OxSVB5UBFaCFJUUFoZWLannUw=s64","userId":"14139449971073476462"}},"outputId":"9f051033-800c-4f1e-82d3-2789939fbcbc"},"source":["model.summary()"],"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_16 (Conv2D)           (None, 254, 254, 32)      896       \n","_________________________________________________________________\n","conv2d_17 (Conv2D)           (None, 252, 252, 64)      18496     \n","_________________________________________________________________\n","max_pooling2d_11 (MaxPooling (None, 126, 126, 64)      0         \n","_________________________________________________________________\n","dropout_11 (Dropout)         (None, 126, 126, 64)      0         \n","_________________________________________________________________\n","conv2d_18 (Conv2D)           (None, 124, 124, 64)      36928     \n","_________________________________________________________________\n","max_pooling2d_12 (MaxPooling (None, 62, 62, 64)        0         \n","_________________________________________________________________\n","dropout_12 (Dropout)         (None, 62, 62, 64)        0         \n","_________________________________________________________________\n","conv2d_19 (Conv2D)           (None, 60, 60, 128)       73856     \n","_________________________________________________________________\n","max_pooling2d_13 (MaxPooling (None, 30, 30, 128)       0         \n","_________________________________________________________________\n","dropout_13 (Dropout)         (None, 30, 30, 128)       0         \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 115200)            0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 64)                7372864   \n","_________________________________________________________________\n","dropout_14 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 7,503,105\n","Trainable params: 7,503,105\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"ifoMrtdFI9SJ"},"source":["#train our model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5cqaFGU6JCg2","executionInfo":{"status":"ok","timestamp":1633499479954,"user_tz":-330,"elapsed":22842,"user":{"displayName":"Sūråj Bhanarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuO4qvUng3Kq2OxSVB5UBFaCFJUUFoZWLannUw=s64","userId":"14139449971073476462"}},"outputId":"46f825e7-b380-49d9-935e-606e41e6a70f"},"source":["model.fit_generator(train_data, steps_per_epoch= 8, epochs = 10, validation_steps= 2,\n","                    validation_data = test_data\n","                    )"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","4/8 [==============>...............] - ETA: 17s - loss: 8.8748e-27 - acc: 1.0000WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 80 batches). You may need to use the repeat() function when building your dataset.\n","8/8 [==============================] - 22s 2s/step - loss: 8.8748e-27 - acc: 1.0000 - val_loss: -95.5197 - val_acc: 0.4688\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f0face51150>"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"6AMUSjK1KvXx"},"source":["take random image and chack"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XVkb-nPcKzcH","executionInfo":{"status":"ok","timestamp":1633501869031,"user_tz":-330,"elapsed":773,"user":{"displayName":"Sūråj Bhanarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuO4qvUng3Kq2OxSVB5UBFaCFJUUFoZWLannUw=s64","userId":"14139449971073476462"}},"outputId":"4608b7a2-1423-4f2f-ca2b-c5cbd2b83ae2"},"source":["path = \"/content/dataset/test/negative cases/1094.png\" \n","img = image.load_img(path, target_size=(256,256)) #this will load our img\n","\n","img = image.img_to_array(img)/256  #we convert img into matrix bcz we want img in numbers\n","img = np.array([img]) \n","img.shape\n","\n"],"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 256, 256, 3)"]},"metadata":{},"execution_count":56}]},{"cell_type":"markdown","metadata":{"id":"GUWoQmS7M677"},"source":["predict our img"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Ub4XMLPM9bC","executionInfo":{"status":"ok","timestamp":1633501873336,"user_tz":-330,"elapsed":753,"user":{"displayName":"Sūråj Bhanarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuO4qvUng3Kq2OxSVB5UBFaCFJUUFoZWLannUw=s64","userId":"14139449971073476462"}},"outputId":"7d1cb853-a9fc-4ea9-fe1c-6ef18534ecd4"},"source":["#y_pred = model.predict(np.expand_dims(img,axis=0))\n","model.predict(img)\n","y_pred = model.predict(img)\n","y_pred = np.round(y_pred).astype(int) \n","y_pred"],"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1]])"]},"metadata":{},"execution_count":57}]}]}